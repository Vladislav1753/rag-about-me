# RAG: About Me â€“ Streamlit Demo

This is a personal Q&A web app powered by Retrieval-Augmented Generation (RAG), where users can ask questions about me â€” my background, skills, projects, and more â€” and receive semantically grounded answers based on uploaded documents.

The goal is to demonstrate how LLMs can be combined with vector search to create a knowledge-based assistant that answers contextually accurate questions, even from unstructured personal data.

---

## Deployment 

The app is deployed via **Google Cloud Run** and publicly accessible here:
https://who-is-vlad.streamlit.app/

## ğŸ” How it works

1. **Document loading** â€“ Text file containing info about me is loaded and chunked.
2. **Embedding** â€“ Chunks are converted into dense vector embeddings using Hugging Face model "sentence-transformers/all-MiniLM-L6-v2".
3. **Indexing** â€“ Vectors are stored in a FAISS vector store for efficient retrieval.
4. **RAG pipeline** â€“ On user query, relevant chunks are retrieved and passed to the language model to generate an answer.
5. **Streamlit UI** â€“ The frontend is built with Streamlit for quick and interactive deployment.

---

